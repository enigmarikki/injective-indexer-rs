version: '3'

services:
  # gRPC client
  grpc-client:
    build:
      context: .
      dockerfile: Dockerfile.grpc.client
    container_name: grpc-client
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - GRPC_STREAM_ENDPOINT=http://host.docker.internal:9999
      - GRPC_QUERY_ENDPOINT=http://host.docker.internal:9900
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_TOPIC=injective-data
      - KAFKA_CLIENT_ID=injective-client
    volumes:
      - ./logs/grpc-client:/logs
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
        compress: "true"
    networks:
      - app-network
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Zookeeper service
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    user: "0:0"  # Run as root to avoid permission issues
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_LOG4J_ROOT_LOGLEVEL: WARN
    volumes:
      - ./zookeeper-data:/var/lib/zookeeper/data
      - ./logs/zookeeper:/logs
    logging:
      driver: "none"  # Disable logging completely
    healthcheck:
      test: ["CMD-SHELL", "echo stat | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network

  # Kafka service
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    volumes:
      - ./kafka-data:/var/lib/kafka/data
      - ./logs/kafka:/logs
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      # Add log reduction settings
      KAFKA_LOG_RETENTION_HOURS: 1
      KAFKA_LOG_RETENTION_BYTES: 10000000  # 10MB
      KAFKA_LOG_SEGMENT_BYTES: 5000000     # 5MB
      KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
      KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
        compress: "true"
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks:
      - app-network

  # Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8001:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=injective-cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
      - LOG_LEVEL=WARN
    logging:
      driver: "none"  # Disable logging completely
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - app-network

  # Dragonfly - Redis compatible database (no password required)
  dragonflydb:
    image: 'docker.dragonflydb.io/dragonflydb/dragonfly'
    container_name: dragonflydb
    ulimits:
      memlock: -1
    ports:
      - "6381:6379"
    volumes:
      - ./dragonfly-data:/data
      - ./logs/dragonflydb:/logs
    command: '--logtostderr=false --alsologtostderr=false --minloglevel=1'
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
        compress: "true"
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "-h", "localhost", "-p", "6379", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  # ScyllaDB - Cassandra compatible database
  scylladb:
    image: scylladb/scylla:5.2
    container_name: scylladb
    user: "0:0"  # Run as root to avoid permission issues
    ports:
      - "9042:9042"
    volumes:
      - ./scylla-data:/var/lib/scylla
      - ./logs/scylladb:/logs
    # Removed the invalid logger options
    command: >
      --smp 1 --memory 1G --overprovisioned 1 --developer-mode 1 --api-address 0.0.0.0
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
        compress: "true"
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "nodetool status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ScyllaDB initialization
  scylla-init:
    image: scylladb/scylla:5.2
    container_name: scylla-init
    depends_on:
      scylladb:
        condition: service_healthy
    volumes:
      - ./scripts/init-scylladb.sh:/init-scylladb.sh
    logging:
      driver: "none"  # Disable logging completely
    entrypoint: ["/bin/bash", "/init-scylladb.sh"]
    networks:
      - app-network

  # Injective processor application
  injective-consumer:
    build:
      context: .
      dockerfile: Dockerfile.consumer
    container_name: injective-consumer
    depends_on:
      dragonflydb:
        condition: service_healthy
      scylla-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
      grpc-client:
        condition: service_started
    environment:
      - RUST_LOG=warn  # Reduced logging level
      - CONFIG_FILE=/app/config/config.json
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_TOPIC=injective-data
      - KAFKA_CONSUMER_GROUP=injective-consumers
      - KAFKA_REDIS_CONSUMER_GROUP=injective-consumers-redis
      - KAFKA_SCYLLADB_CONSUMER_GROUP=injective-consumers-scylladb
      - REDIS_URL=redis://dragonflydb:6379
      - SCYLLADB_NODES=scylladb:9042
      - GRPC_STREAM_ENDPOINT=http://host.docker.internal:9999
      - GRPC_QUERY_ENDPOINT=http://host.docker.internal:9900
    volumes:
      - ./config:/app/config
      - ./logs/injective-consumer:/app/logs
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
        compress: "true"
    networks:
      - app-network
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"

networks:
  app-network:
    driver: bridge